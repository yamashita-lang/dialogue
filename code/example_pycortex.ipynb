{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cortical maps using Pycortex "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cortex\n",
    "import numpy as np\n",
    "import sys\n",
    "import h5py\n",
    "import os\n",
    "import tables\n",
    "\n",
    "# sys.path.append('/_path_to_/config.py')\n",
    "from config import DATA_DIR, RESULT_DIR, SUBJECTS_ALL, TOTAL_SESS, LAYERS, CL, NVOXELS\n",
    "from pycortex.utils_pycortex import (\n",
    "    get_volume_neg2nan_ALLSUBJ_base, get_volume_context_neg2nan_ALLSUBJ,\n",
    "    get_volume_cross_context_neg2nan_ALLSUBJ, get_volume2D_bestvp_neg2nan_ALLSUBJ,\n",
    "    get_volume2D_context_weightcorr_bothsignificant, get_volume_weightcorr_VP_mask,\n",
    "    get_volume2D_context_all_weightcorr_significant_unified_diff\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Following result files from Natural Dialogue fMRI Dataset are available via OpenNeuro (https://openneuro.org/datasets/ds004669)\n",
    "\n",
    "### Head Motion model results\n",
    "head_motion_model_file=f\"{RESULT_DIR}ALLSUBJ_sig_brainscore_step1_headmotion.hdf\"\n",
    "\n",
    "### Random embedding model results\n",
    "random_model_file=f\"{RESULT_DIR}ALLSUBJ_sig_brainscore_step2_randnormal.hdf\"\n",
    "\n",
    "### Low-level model results\n",
    "lowlevel_model_file=f\"{RESULT_DIR}ALLSUBJ_sig_brianscore_step3_lowlevel.hdf\"\n",
    "\n",
    "### Separate Linguistic model results\n",
    "separate_model_file=f\"{RESULT_DIR}ALLSUBJ_sig_brainscore_step3_intramodal.hdf\"\n",
    "\n",
    "### Separate Linguistic model cross-modality prediction results\n",
    "cross_modality_file=f\"{RESULT_DIR}ALLSUBJ_sig_brainscore_step3_crossmodal.hdf\"\n",
    "\n",
    "### Unified Linguistic model results\n",
    "unified_model_file=f\"{RESULT_DIR}ALLSUBJ_sig_brainscore_step3_unified.hdf\"\n",
    "\n",
    "### Best variance partition results\n",
    "bestbp_file=f\"{RESULT_DIR}ALLSUBJ_best_varpart.hdf\"\n",
    "\n",
    "### Weight correlation in the Separate Linguistic model weights\n",
    "wc_sep_file=f\"{RESULT_DIR}ALLSUBJ_weightcorrs_gpt_separate.hdf\"\n",
    "\n",
    "### Weight correlation similarity between the Separate Linguistic model weights with Unified Linguistic model weights\n",
    "wc_unif_sep_file=f\"{RESULT_DIR}ALLSUBJ_weightcorrs_gpt_unified.hdf\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction accuracy (brain score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Head Motion model/Random normal embedding model/Low-level sensory model (Supplementary Figs.3-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap='inferno'\n",
    "VMAX=0.3\n",
    "\n",
    "### files\n",
    "# head_motion_model_file=f\"{RESULT_DIR}ALLSUBJ_sig_brainscore_step1_headmotion.hdf\"\n",
    "# random_model_file=f\"{RESULT_DIR}ALLSUBJ_sig_brainscore_step2_randnormal.hdf\"\n",
    "# lowlevel_model_file=f\"{RESULT_DIR}ALLSUBJ_sig_brianscore_step3_lowlevel.hdf\"\n",
    "\n",
    "\n",
    "volumes={}\n",
    "for subject_idx in range(8):\n",
    "    subject = SUBJECTS_ALL[subject_idx]\n",
    "\n",
    "    ### Head Motion model\n",
    "    fig_name=f\"{subject}_headmotion\"\n",
    "    if os.path.exists(head_motion_model_file):\n",
    "        volumes[fig_name]=get_volume_neg2nan_ALLSUBJ_base(subject_idx, subject, head_motion_model_file, cmap=cmap, vmax=VMAX)\n",
    "    else:\n",
    "        print(f\"Not available {head_motion_model_file}\")\n",
    "\n",
    "    ### Random embedding model\n",
    "    fig_name=f\"{subject}_random\"\n",
    "    if os.path.exists(random_model_file):\n",
    "        volumes[fig_name]=get_volume_neg2nan_ALLSUBJ_base(subject_idx, subject, random_model_file, cmap=cmap, vmax=VMAX)\n",
    "    else:\n",
    "        print(f\"Not available {random_model_file}\")\n",
    "\n",
    "    ### Low-level model\n",
    "    fig_name=f\"{subject}_lowlevel\"\n",
    "    if os.path.exists(lowlevel_model_file):\n",
    "        volumes[fig_name]=get_volume_neg2nan_ALLSUBJ_base(subject_idx, subject, lowlevel_model_file, cmap=cmap, vmax=VMAX)\n",
    "    else:\n",
    "        print(f\"Not available {lowlevel_model_file}\")\n",
    "    \n",
    "im =cortex.webshow(volumes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separte and Unified Linguistic model (Fig 2a, Supplementary Figs 6-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap='hot'\n",
    "\n",
    "THR=0\n",
    "VMIN=0\n",
    "VMAX=0.3\n",
    "\n",
    "################################################################################################\n",
    "volumes={}\n",
    "for subject_idx in range(8):\n",
    "    subject = SUBJECTS_ALL[subject_idx]\n",
    "    for layer_idx, layer in enumerate(LAYERS):\n",
    "        if layer == 18:\n",
    "            for cl_idx, cl in enumerate(CL):\n",
    "                # if cl in [1]:\n",
    "                if cl in [1, 8, 32]:\n",
    "                    ### Separate Linguistic model \n",
    "                    # separate_model_file=f\"{RESULT_DIR}ALLSUBJ_sig_brainscore_step3_intramodal.hdf\"\n",
    "                    # cross_modality_file=f\"{RESULT_DIR}ALLSUBJ_sig_brainscore_step3_crossmodal.hdf\"\n",
    "                    # unified_model_file=f\"{RESULT_DIR}ALLSUBJ_sig_brainscore_step3_unified.hdf\"\n",
    "                    test_idx=1\n",
    "                    ### Separate Linguistic model same-modality\n",
    "                    if os.path.exists(separate_model_file):\n",
    "                        fig_name=f\"{subject}_Separete_L-{layer}_CL-{cl}\"\n",
    "                        volumes[fig_name]=get_volume_context_neg2nan_ALLSUBJ(subject_idx, subject, layer_idx, cl_idx, test_idx, separate_model_file, cmap=cmap, vmin=VMIN, vmax=VMAX, thr=THR)\n",
    "                    else:\n",
    "                        print(f\"Not available {separate_model_file}\")\n",
    "\n",
    "                    ### Separate Linguistic model cross-modality\n",
    "                    if os.path.exists(cross_modality_file):\n",
    "                        fig_name=f\"{subject}_Cross_L-{layer}_CL-{cl}\"\n",
    "                        volumes[fig_name]=get_volume_cross_context_neg2nan_ALLSUBJ(subject_idx, subject, layer_idx, cl_idx, cross_modality_file, separate_model_file, cmap=cmap, vmin=VMIN, vmax=VMAX, thr=THR)\n",
    "                    else:\n",
    "                        print(f\"Not available {cross_modality_file}\")\n",
    "\n",
    "                    ### Unified Linguistic model\n",
    "                    if os.path.exists(unified_model_file):\n",
    "                        fig_name=f\"{subject}_Unified_L-{layer}_CL-{cl}\"\n",
    "                        volumes[fig_name]=get_volume_context_neg2nan_ALLSUBJ(subject_idx, subject, layer_idx, cl_idx, test_idx, unified_model_file, cmap=cmap, vmin=VMIN, vmax=VMAX, thr=THR)\n",
    "                    else:\n",
    "                        print(f\"Not available {unified_model_file}\")\n",
    "                    \n",
    "\n",
    "im =cortex.webshow(volumes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance partitioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best variance partitioning (Fig 4c, Supplementary Fig 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap=\"BROYG_2D\"\n",
    "\n",
    "# bestbp_file=f\"{RESULT_DIR}ALLSUBJ_best_varpart.hdf\"\n",
    "# separate_model_file=f\"{RESULT_DIR}ALLSUBJ_sig_brainscore_step3_intramodal.hdf\"\n",
    "THR=0.05\n",
    "VMAX=0.2\n",
    "\n",
    "volumes={}\n",
    "for subject_idx in range(8):\n",
    "    subject = SUBJECTS_ALL[subject_idx]    \n",
    "    for layer_idx, layer in enumerate(LAYERS):\n",
    "        if layer == 18:\n",
    "            for cl_idx, cl in enumerate(CL):\n",
    "                if cl in [1, 8, 32]:\n",
    "                    fig_name=f\"{subject}_l-{layer}_s-{cl}\"\n",
    "                    volumes[fig_name]=get_volume2D_bestvp_neg2nan_ALLSUBJ(subject_idx, subject, layer_idx, cl_idx, bestbp_file, separate_model_file, vmin=THR, vmax=VMAX, thr=THR, cmap=cmap)\n",
    "\n",
    "im =cortex.webshow(volumes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WC in cross-modal voxels, bimodal voxels, and differences (Fig 2c/SFig 14, 3d/SFig 15, 4e/SFig 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### parameters\n",
    "TARGET_LAYER=18\n",
    "\n",
    "##########################################################################################\n",
    "volumes={}\n",
    "for subject_idx in range(8):\n",
    "    subject = SUBJECTS_ALL[subject_idx]\n",
    "    for cl_idx, cl in enumerate(CL):\n",
    "        if cl in [1, 8, 32]:\n",
    "            for layer_idx, layer in enumerate(LAYERS):\n",
    "                if layer == TARGET_LAYER:\n",
    "                    ### cross-modal voxels\n",
    "                    ## Fig. 2c WC in cross-modal voxels (Supplementary Fig 13)\n",
    "                    fig_name=f\"{subject}_l-{layer}_{cl}_crossmodal_voxels\"\n",
    "                    cmap=\"BuWtRd_alpha\"\n",
    "                    WC_MAX=0.4\n",
    "                    SCORE_MIN=0.05\n",
    "                    SCORE_MAX=0.2\n",
    "                    volumes[fig_name] = get_volume2D_context_weightcorr_bothsignificant(subject, subject_idx, layer_idx, cl_idx, wc_sep_file, separate_model_file, cross_modality_file, \n",
    "                                                                                vmin=-WC_MAX, vmax=WC_MAX, score_min=SCORE_MIN, score_max=SCORE_MAX, cmap=cmap)\n",
    "\n",
    "                    ### bimodal voxels\n",
    "                    modality_idx=3\n",
    "                    ## Fig. 4e WC in bimodal voxels (Supplementary Fig 16)\n",
    "                    fig_name=f\"{subject}_l-{layer}_{cl}_bimodal_voxels\"\n",
    "                    volumes[fig_name] = get_volume_weightcorr_VP_mask(subject, subject_idx, layer_idx, cl_idx, modality_idx, wc_sep_file, bestbp_file, separate_model_file, \n",
    "                                                                                vmin=-WC_MAX, vmax=WC_MAX, cmap=cmap)\n",
    "\n",
    "                    \n",
    "                    ### wc differences \n",
    "                    ## Fig 3d WC difference between Unified model weights and Separate model weights (comp - prod) in unified scores (Supplementary Fig 14)\n",
    "                    fig_name=f\"{subject}_l-{layer}_{cl}_diff\"\n",
    "                    cmap=\"BuBkRd_alpha_2D\"\n",
    "                    WC_MAX=0.3\n",
    "                    SCORE_MIN=0.05\n",
    "                    SCORE_MAX=0.3\n",
    "                    volumes[fig_name] = get_volume2D_context_all_weightcorr_significant_unified_diff(subject, subject_idx, layer_idx, cl_idx, wc_unif_sep_file, separate_model_file, unified_model_file, \n",
    "                                                                                vmin=-WC_MAX, vmax=WC_MAX, score_min=SCORE_MIN, score_max=SCORE_MAX, cmap=cmap)\n",
    "\n",
    "im =cortex.webshow(volumes)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
